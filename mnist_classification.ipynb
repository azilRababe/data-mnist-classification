{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ <b><u>Exercise objectives</u></b>\n",
    "- Understand the *MNIST* dataset \n",
    "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
    "    - what are *Convolutional Layers*? \n",
    "    - how many *parameters* are involved in such a layer?\n",
    "- Train this CNN on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ <b><u>Let's get started!</u></b>\n",
    "\n",
    "Imagine that we are  back in time into the 90's.\n",
    "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits? \n",
    "\n",
    "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
    "\n",
    "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Number recognition](recognition.gif)\n",
    "\n",
    "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î <b><u>How does this CNN work ?</u></b>\n",
    "\n",
    "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
    "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
    "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
    "\n",
    "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) The `MNIST` Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
    "- *Vectors*: `boston_housing` (regression)\n",
    "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
    "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
    "\n",
    "\n",
    "üíæ You can **load the MNIST dataset** with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 12:37:20.938083: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 12:37:21.212181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-22 12:37:21.212201: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-22 12:37:21.261545: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-22 12:37:22.701747: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 12:37:22.701891: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-22 12:37:22.701905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import datasets\n",
    "\n",
    "\n",
    "# Loading the MNIST Dataset...\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "# The train set contains 60 000 images, each of them of size 28x28\n",
    "# The test set contains 10 000 images, each of them of size 28x28\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
    "\n",
    "üñ® Print some images from the *train set*.\n",
    "\n",
    "<details>\n",
    "    <summary><i>Hints</i></summary>\n",
    "\n",
    "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
    "\n",
    "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAB/CAYAAACQeNq9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAXrklEQVR4nO3dfVCVVR4H8C8iAsrbgqhlSZGouWGZCi5riqFrKRYmSbVplltOvsQ44rq6puxua75hvhujU0o6wzooVlab7Yrby7KIle5QQaQSYQ6BBGi+Lcuzf7T++l0B773A5d7n3u9nhpnvvTz3eQ73ePFwznPO8TIMwwARERF5tE7OLgARERE5HxsERERExAYBERERsUFAREREYIOAiIiIwAYBERERgQ0CIiIiAhsEREREBDYIiIiICCZoEJSVlcHLywtr1qxpt3MePnwYXl5eOHz4cLud09OwXlwX68Y1sV5cF+vmRw5pEOzYsQNeXl44evSoI07vdOnp6fDy8mry5efn5+yiXZe71wsAnD59GlOmTEFISAiCgoLw4IMP4uTJk84ullWeUDfa2LFj4eXlhTlz5ji7KNfl7vVSUlKCefPmIS4uDn5+fvDy8kJZWZmzi2UTd68bAMjOzsbdd98NPz8/hIeHY8aMGaiurnbY9To77MweYOvWrQgICJDH3t7eTiwNnT9/HqNHj0ZdXR0WL14MHx8fvPTSSxg1ahSOHTuGsLAwZxeRAOzbtw/5+fnOLgYByM/Px4YNGzBw4EDcfvvtOHbsmLOLRP+3detWzJo1CwkJCVi7di0qKiqwfv16HD16FAUFBQ75A5QNgjZITk5G9+7dnV0M+r8tW7agtLQUR44cwbBhwwAA999/P+644w5kZGRg+fLlTi4hXbp0CfPnz8fChQuxdOlSZxfH4z3wwAOora1FYGAg1qxZwwaBi7hy5QoWL16MkSNH4r333oOXlxcAIC4uDhMnTsS2bdswd+7cdr+u0+4huHLlCpYuXYohQ4YgODgY3bp1wz333IO8vLwWX/PSSy8hIiIC/v7+GDVqFIqKipocU1xcjOTkZISGhsLPzw9Dhw7FG2+8YbU8Fy5cQHFxsV3dMYZhoL6+Hu60YaSZ6yUnJwfDhg2TxgAADBgwAAkJCdizZ4/V17s6M9fNVatWrUJjYyPS0tJsfo2rM3O9hIaGIjAw0OpxZmXWuikqKkJtbS1SUlKkMQAAiYmJCAgIQHZ2ttVrtYbTGgT19fXYvn074uPjsXLlSqSnp6Oqqgrjxo1rtpWalZWFDRs2YPbs2Vi0aBGKiopw7733orKyUo757LPPMHz4cHzxxRf43e9+h4yMDHTr1g1JSUnIzc29bnmOHDmC22+/HZs2bbL5Z4iMjERwcDACAwPx+OOPW5TFrMxaL42Njfj3v/+NoUOHNvleTEwMTpw4gXPnztn2Jrgos9bNVeXl5VixYgVWrlwJf39/u352V2b2enFnZq2by5cvA0CznxN/f398+umnaGxstOEdsJPhAK+++qoBwCgsLGzxmIaGBuPy5csWz33//fdGz549jaeeekqeO3XqlAHA8Pf3NyoqKuT5goICA4Axb948eS4hIcGIjo42Ll26JM81NjYacXFxRlRUlDyXl5dnADDy8vKaPLds2TKrP9+6deuMOXPmGLt37zZycnKM1NRUo3PnzkZUVJRRV1dn9fXO4s71UlVVZQAw/vjHPzb53ubNmw0ARnFx8XXP4UzuXDdXJScnG3FxcfIYgDF79mybXussnlAvV61evdoAYJw6dcqu1zmLO9dNVVWV4eXlZcyYMcPi+eLiYgOAAcCorq6+7jlaw2k9BN7e3ujSpQuAH/+6q6mpQUNDA4YOHYpPPvmkyfFJSUno3bu3PI6JiUFsbCzefvttAEBNTQ0OHTqEKVOm4Ny5c6iurkZ1dTXOnj2LcePGobS0FKdPn26xPPHx8TAMA+np6VbLnpqaio0bN+Kxxx7D5MmTsW7dOuzcuROlpaXYsmWLne+EazFrvVy8eBEA4Ovr2+R7V2++uXqMWZm1bgAgLy8Pe/fuxbp16+z7oU3AzPXi7sxaN927d8eUKVOwc+dOZGRk4OTJk/jggw+QkpICHx8fAI75febUdQh27tyJQYMGwc/PD2FhYQgPD8dbb72Furq6JsdGRUU1ea5fv34yRearr76CYRh4/vnnER4ebvG1bNkyAMB3333nsJ/lscceQ69evfC3v/3NYdfoKGasl6tda1e72rRLly5ZHGNmZqybhoYGPPfcc5g6darF/R3uxIz14inMWjeZmZkYP3480tLScNttt2HkyJGIjo7GxIkTAcBihlt7cdosg127dmH69OlISkrCggUL0KNHD3h7e+PFF1/EiRMn7D7f1fGUtLQ0jBs3rtlj+vbt26YyW3PzzTejpqbGoddwNLPWS2hoKHx9fXHmzJkm37v63I033tjm6ziTWesmKysLJSUlyMzMbDLH/dy5cygrK0OPHj3QtWvXNl/LGcxaL57AzHUTHByM119/HeXl5SgrK0NERAQiIiIQFxeH8PBwhISEtMt1NKc1CHJychAZGYl9+/ZZ3EV5tZV1rdLS0ibPffnll7jlllsA/HiDHwD4+PhgzJgx7V9gKwzDQFlZGQYPHtzh125PZq2XTp06ITo6utlFSgoKChAZGWn6u6nNWjfl5eX4z3/+g1/+8pdNvpeVlYWsrCzk5uYiKSnJYWVwJLPWiydwh7rp06cP+vTpAwCora3Fxx9/jMmTJzvkWk69hwCAxZS9goKCFhcs2b9/v8XYzJEjR1BQUID7778fANCjRw/Ex8cjMzOz2b8Sq6qqrlsee6bqNHeurVu3oqqqCvfdd5/V17syM9dLcnIyCgsLLRoFJSUlOHToEB5++GGrr3d1Zq2bRx55BLm5uU2+AGD8+PHIzc1FbGzsdc/hysxaL57A3epm0aJFaGhowLx581r1emsc2kPwyiuv4K9//WuT51NTU5GYmIh9+/Zh0qRJmDBhAk6dOoWXX34ZAwcOxPnz55u8pm/fvhgxYgSeffZZXL58GevWrUNYWBh++9vfyjGbN2/GiBEjEB0djaeffhqRkZGorKxEfn4+KioqcPz48RbLeuTIEYwePRrLli2zesNHREQEUlJSEB0dDT8/P3z44YfIzs7GXXfdhZkzZ9r+BjmJu9bLrFmzsG3bNkyYMAFpaWnw8fHB2rVr0bNnT8yfP9/2N8iJ3LFuBgwYgAEDBjT7vVtvvdUUPQPuWC8AUFdXh40bNwIAPvroIwDApk2bEBISgpCQEJdfWhpw37pZsWIFioqKEBsbi86dO2P//v04ePAgXnjhBcfdi9Pu8xaMn6aDtPT1zTffGI2Njcby5cuNiIgIw9fX1xg8eLBx4MAB44knnjAiIiLkXFeng6xevdrIyMgwbr75ZsPX19e45557jOPHjze59okTJ4xp06YZvXr1Mnx8fIzevXsbiYmJRk5OjhzT1qk6v/nNb4yBAwcagYGBho+Pj9G3b19j4cKFRn19fVveNodz93oxDMP45ptvjOTkZCMoKMgICAgwEhMTjdLS0ta+ZR3GE+rmWjDRtEN3rZerZWruS5fdFbl73Rw4cMCIiYkxAgMDja5duxrDhw839uzZ05a3zCovw3CjZfaIiIioVVx++2MiIiJyPDYIiIiIiA0CIiIiYoOAiIiIwAYBERERgQ0CIiIigh0LE+llH6n9tMesT9aNY7S1blgvjsHPjOviZ8Y12Vov7CEgIiIiNgiIiIiIDQIiIiICGwREREQENgiIiIgIbBAQERER2CAgIiIisEFAREREYIOAiIiIwAYBERERgQ0CIiIigh17GRC1tyFDhkieM2eO5GnTpknOysqSvHHjRsmffPKJg0tHRORZ2ENAREREbBAQERER4GXYuC+iK25L6e3tLTk4ONjq8bpbumvXrpL79+8vefbs2ZLXrFkj+dFHH7U416VLlySvWLFC8h/+8Aer5dA8bSvXu+66S/KhQ4ckBwUFWX1tXV2d5LCwsHYtV3O4lav9EhISJO/evdvie6NGjZJcUlLS6mt42mfGXkuWLJGsfx916vTT33/x8fEWr/nHP/7RLtfmZ8Y1cftjIiIishkbBERERORaswz69OkjuUuXLpLj4uIkjxgxQnJISIjkyZMnt/q6FRUVkjds2CB50qRJks+dO2fxmuPHj0tur+42dxUTEyN57969kvUwj+7S0u/1lStXJOthguHDh0u+dsaBfo2ZjBw5UrL+WXNzc51RnFYZNmyY5MLCQieWxLNMnz5d8sKFCyU3NjY2e3x7DLuQ+2EPAREREbFBQERERE4eMtB3nAOWd53bMmugLXRXmr4r9/z585L1XdJnzpyxeP33338vuS13TLsTPXPj7rvvlrxr1y7JN9xwg9XzlJaWSl61apXk7OxsyR999JFkXX8A8OKLL9pYYtei7/yOioqS7OpDBvru9VtvvVVyRESExXG8g9xx9Hvt5+fnxJK4n9jYWMmPP/64ZD1r5uc//3mzr01LS5P87bffStZD3/r3Y0FBQdsK20bsISAiIiI2CIiIiIgNAiIiIoKT7yEoLy+3eHz27FnJbbmHQI/D1NbWSh49erRkPTXttddea/W16CeZmZmSr13Z0R76/oOAgADJenqnHm8fNGhQq6/lSvSmTvn5+U4siX30fSFPP/20ZD02CgDFxcUdViZPMGbMGMlz585t9hj9nicmJkqurKx0XMHcQEpKiuT169dL7t69u2R9T8zhw4clh4eHS169enWz59ev1cc/8sgjrStwO2EPAREREbFBQERERE4eMqipqbF4vGDBAsm6e+vTTz+VrFcS1I4dOyZ57Nixkn/44QfJempIamqq/QWmJoYMGSJ5woQJkluaYqa7/d98803JeiMpPT1H172e6nnvvfdavZbZ6Ol7ZrJ9+/Zmn9fTR6l96Olqr776quSWhlh1l/XXX3/tuIKZVOfOP/0XOHToUMnbtm2TrKdTv//++5L/9Kc/Sf7www8l+/r6St6zZ4/kX/3qV82W4ejRo/YW22HM+RuIiIiI2hUbBERERORamxvt379fsl61UG92c+edd0qeMWOGZN3lrIcJtM8++0zyM88806ayejK9wuR7770nOSgoSLLePOWdd96RrGcf6JW+9GqDugu6qqpKst5QSq80qYcqAMtZCtdufORq9AyJnj17OrEkrddSd7X+t0Ht44knnpB84403NnuMvuM9KyvL0UUyNb3yYEtDX/rfsZ59UF9f3+zx+piWhgn0hno7d+60rbAdgD0ERERExAYBERERudiQgdZSd0xdXV2zz+sFUf7yl79Ibmk/cLJPv379JOvZILq7uLq6WrLeDEp3ienNo956661ms738/f0tHs+fP1/yr3/961aftyOMHz9e8rU/hyvTwxt6QyPt9OnTHVUct6YXw3nqqack699tegG2F154oUPKZVZ6dsDixYsl62HOLVu2SNbDmS39v6T9/ve/t3rMc889J1kPizobewiIiIiIDQIiIiJy4SGDlqSnp0vWi+LoO9b1Gt8HDx7skHK5G724BmA5i0N3c+sZIHotfr3YRkd3hffp06dDr9cW/fv3b/Z5PSPGFel/D3r44Msvv5Ss/22QfW655RbJe/futXr8xo0bJefl5TmiSKa1dOlSi8d6mEDvafPuu+9KXrhwoeSLFy82e14/Pz/JejaB/v2jF03TQzmvv/66TWXvaOwhICIiIjYIiIiIyIRDBnrRIT2zQC9Ao9eh1t1nuht78+bNkvXdpfSjwYMHWzzWwwTagw8+KFnvU0BtU1hY6LRr6wWm7rvvPsl6EZeWFlzRd3DrO9/JPvp9b2l777///e+S9Ra9BISEhEieNWuWxff073s9TJCUlGT1vH379pW8e/duyXr4WsvJyZG8atUqq+d3NvYQEBERERsEREREZMIhA+3EiROSp0+fLllvCzp16tRmc7du3STr9b71gjqebO3atRaP9d2yemjAWcMEeqtgd1x8KjQ01O7X6H0+dH3pWTc33XST5C5dukjWCzjp91bfYV1QUCD58uXLkvUWsh9//LHd5aYf6S7rFStWNHuM3mZX72vQ0oJtnkr/29YLO11LLxDUo0cPyU8++aTkBx54QPIdd9whOSAgQLIehtB5165dklvaY8eVsIeAiIiI2CAgIiIikw8ZaLm5uZJLS0sl667vhIQEycuXL5ccEREh+c9//rNkT1uLPTExUbLe4hiw7AZ74403OqpILdLDBNfOEjl27FgHl6b1dJe8/jlefvllyXohlevRd6PrIYOGhgbJFy5ckPz5559LfuWVVyTr2Th6SKiyslKy3r5VLzxVXFxsU1npR/YuQHTy5EnJuj7Ikl5w6Nq9AsLDwyWfOnVKsi2zzb799lvJel+DG264QbLe0+XNN9+0scSugT0ERERExAYBERERudGQgVZUVCR5ypQpkidOnChZz0SYOXOm5KioKMljx451VBFdku761XfpAsB3330nWW8v7Wh6TwW9j4V26NAhi8eLFi1yZJHalV405euvv5YcFxdn97nKy8sl79+/X/IXX3wh+V//+pfd573qmWeekay7XXU3NtlHr5lvy2yZlmYfkCW9KNa1Cw4dOHBAsp7No2et6b0GduzYIbmmpkZydna2ZD1koJ83G/YQEBERERsERERE5KZDBpruOnrttdckb9++XbJeWGXkyJGS4+PjJR8+fNgh5TMLvRCNoxdv0sMES5YskbxgwQLJ+i73jIwMi9efP3/egaVznJUrVzq7CNelZ+lottwdTz/RM3ha2hNC093XJSUljiiSW9MLagGWw1320v8/jBo1SrIe7jHzEBp7CIiIiIgNAiIiInLTIQO9QEtycrLkYcOGSdbDBJperOX99993QOnMydGLEeluVD00kJKSIll3nU6ePNmh5SHb6UXByLqDBw9K/tnPftbsMXo2iN6nhZxLz8RqaXE0zjIgIiIiU2ODgIiIiMw9ZNC/f3/Jc+bMkfzQQw9J7tWrl9Xz/Pe//5Ws76B3x211r0evf68zYLm4R2pqartcb968eZKff/55ycHBwZJ3794tedq0ae1yXSJnCgsLk9zS75gtW7ZINuusGXf07rvvOrsIDsUeAiIiImKDgIiIiEwyZKC7/R999FHJephAbyNqC73Fq97y2BW29nUWfafstVuB6jrYsGGDZL1t7tmzZyUPHz5c8tSpUyXfeeedkm+66SbJeh1+3S2nu07JdeghpX79+kluy14J7kzvndKpk/W/w/75z386sjjUSuPGjXN2ERyKPQRERETEBgERERG52JBBz549JQ8cOFDypk2bJA8YMMCuc+p1rFevXi1ZL3LjabMJWsPb21uy3rJXLxBUX18vWW8j3RLdLZqXlyd56dKlrS4ndQw9pGRLF7gn0ottjRkzRrL+fXPlyhXJmzdvllxZWenYwlGrREZGOrsIDsVPMhEREbFBQERERGwQEBEREZxwD0FoaKjkzMxMi+/pMTd7x2r0eHRGRoZkPYXt4sWLdp3T0+Tn50suLCy0+J7eGErT0xH1PSCano6oN/5orxUPybl+8YtfSN6xY4fzCuJiQkJCJLe0Yurp06clp6WlObpI1EYffPCBZH3vjLvch8YeAiIiImKDgIiIiBw4ZBAbGytZ728fExMjuXfv3naf98KFC5L1innLly+X/MMPP9h9XgIqKiok6w2iAGDmzJmSlyxZYvVc69evl7x161bJX331VVuKSC7i2s2viDxBUVGR5NLSUsl6iPu2226TXFVV1TEFayfsISAiIiI2CIiIiMiBQwaTJk1qNl/P559/LvnAgQOSGxoaJOsZBLW1tW0oIV3PmTNnLB6np6c3m8lzvPPOO5IffvhhJ5bEHIqLiyXrWVAjRoxwRnGonelh6u3bt0vWm+XNnTtXsv7/zVWxh4CIiIjYICAiIiLAy7h24/uWDuRdxQ5h49t/Xawbx2hr3bBeHIOfGdflSZ+ZoKAgyXv27JGsN7Lat2+f5CeffFJyR8+Es7Ve2ENAREREbBAQERERhwycjt2frsuTuj/NhJ8Z1+Wpnxk9fKBnGTz77LOSBw0aJLmjZxxwyICIiIhsxgYBERERccjA2dj96bo8tfvT1fEz47r4mXFNHDIgIiIim7FBQERERLYPGRAREZH7Yg8BERERsUFAREREbBAQERER2CAgIiIisEFAREREYIOAiIiIwAYBERERgQ0CIiIiAhsEREREBOB/3cBE2BStuqEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images=X_train[:5]\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(1, len(images), i+1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Label: {}'.format(y_train[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
    "\n",
    "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
    "* The `RBG` intensities are coded between 0 and 255. \n",
    "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.** \n",
    "\n",
    "Don't forget to do it both on your train data and your test data.\n",
    "\n",
    "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# Reshape the data to (num_samples, height, width, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Inputs' dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
    "\n",
    "> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
    "\n",
    "> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
    "\n",
    "üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n",
    "<br>\n",
    "<details>\n",
    "    <summary><i>Answer<i></summary>\n",
    "        \n",
    "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
    "        \n",
    "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
    "        \n",
    "    * In comparison, colored pictures need multiple channels:\n",
    "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
    "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
    "        \n",
    "        \n",
    "</details>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: expanding dimensions** ‚ùì\n",
    "\n",
    "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
    "\n",
    "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) Target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing to for a multiclass classification task in Deep Leaning:\n",
    "\n",
    "üëâ _\"one-hot-encode\" the categories*_\n",
    "\n",
    "‚ùì **Question: encoding the labels** ‚ùì \n",
    "\n",
    "* Use **`to_categorical`** to transform your labels. \n",
    "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat=to_categorical(y_train)\n",
    "y_test_cat=to_categorical(y_test)\n",
    "\n",
    "# y_train_cat,y_test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check that you correctly used to_categorical\n",
    "assert(y_train_cat.shape == (60000,10))\n",
    "assert(y_test_cat.shape == (10000,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now ready to be used. ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) The Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Architecture and compilation of a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
    "\n",
    "Now, let's build a <u>Convolutional Neural Network</u> that has: \n",
    "\n",
    "\n",
    "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
    "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
    "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
    "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
    "\n",
    "\n",
    "- a `Flatten` layer\n",
    "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
    "- a last (predictive) layer that is suited for your task\n",
    "\n",
    "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
    "* optimizes the `categorical_crossentropy` loss function,\n",
    "* with the `adam` optimizer, \n",
    "* and the `accuracy` as the metrics\n",
    "\n",
    "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    ### First Convolution & MaxPooling\n",
    "    model.add(layers.Conv2D(8, kernel_size=(4, 4), activation='relu', input_shape=(225, 225, 4),padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2))) \n",
    "   \n",
    "    ### Second Convolution & MaxPooling\n",
    "    model.add(layers.Conv2D(16, (3,3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))     \n",
    "    ### Flattening\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    \n",
    "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
    "    model.add(layers.Dense(10, activation='sigmoid'))\n",
    "    \n",
    "    ### Model compilation\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì \n",
    "\n",
    "How many trainable parameters are there in your model?\n",
    "1. Compute them with ***model.summary( )*** first\n",
    "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 12:37:28.094547: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-22 12:37:28.094587: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-22 12:37:28.094620: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (rababeazil-HP-EliteBook-840-G2): /proc/driver/nvidia/version does not exist\n",
      "2023-02-22 12:37:28.095856: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model=initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 225, 225, 8)       520       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 110, 110, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 55, 55, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                484010    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 485,808\n",
      "Trainable params: 485,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Training a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: training a CNN** ‚ùì \n",
    "\n",
    "Initialize your model and fit it on the train data. \n",
    "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**. \n",
    "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 12:37:50.123903: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 131712000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 225, 225, 4), found shape=(16, 28, 28, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      4\u001b[0m es \u001b[39m=\u001b[39m EarlyStopping()\n\u001b[0;32m----> 6\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, \n\u001b[1;32m      7\u001b[0m           batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, \n\u001b[1;32m      8\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, \n\u001b[1;32m      9\u001b[0m           validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m           callbacks\u001b[39m=\u001b[39;49m[es])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filepe95b65g.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 225, 225, 4), found shape=(16, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "initialize_model()\n",
    "es = EarlyStopping()\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=16, \n",
    "          epochs=5, \n",
    "          validation_split=0.3,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
    "\n",
    "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><i>Answer</i></summary>\n",
    "\n",
    "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
    "    \n",
    "Remember that we've just trained our CNN model on $60000$ training images\n",
    "\n",
    "If the chosen batch size is 32: \n",
    "\n",
    "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
    "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
    "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss` \n",
    "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
    "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
    "\n",
    "\n",
    "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
    "\n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) Evaluating its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: Evaluating your CNN** ‚ùì \n",
    "\n",
    "What is your **`accuracy on the test set?`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 225, 225, 4), found shape=(None, 28, 28, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mevaluate(X_test)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file4umd9g4h.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/training.py\", line 1665, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/rababeazil/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 225, 225, 4), found shape=(None, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
    "\n",
    "üî• You solved what was a very hard problem 30 years ago with your own CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ **Congratulations!**\n",
    "\n",
    "üíæ Don't forget to `git add/commit/push` your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "0bf8b989ad100e871ac34072f3e5140b4e29e833764c113dc3affd3ae1fe812f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
